---
title: 'Virtual Beings: Responsive Characters with Intent and Action'
date: 2022-05-01
permalink: /posts/2020/05/virtual-beings/
tags:
  - bots
  - realtime
  - animation
---

<!-- wp:heading {"level":3} -->
<h3>#VirtualBeings</h3>
<!-- /wp:heading -->

<!-- wp:paragraph -->
<p>Last week, the remnants of [Oculus Story Studio](https://www.theverge.com/2018/1/18/16900862/fable-oculus-story-studio-resurrection-vr-wolves-in-the-walls) (rebranded “Fable”), hosted a small conference to show the world the concept  of an animated character driven by predictive models (AI). Despite it’s small group,Unreal Engine CTO Kim Libreri was in attendance, and a few other notables. They came up  with a fancy hashtag and everything!

Here’s their video teaser:

<figure><iframe src="https://player.vimeo.com/video/313038866?autoplay=0" allowfullscreen="true"></iframe></figure>

I hadn’t heard of this virtual being summit until recently, so I was a  
bit bummed I missed it. It’s a concept that I’ve been thinking about  
for a while now, and would have loved to hear what others in the space
are working on.
The  propagation of voice recognition, chatbots, micro-functions, cloud computing, and the like, has enabled an ecosystem for virtual characters to thrive. Yet, we barely have them among us. I think it’s because (in my opinion) the design of a virtual character
straddles two broad development areas.

I will call each of these development areas “Intent” and “Action.”

Intent
Intent is essentially “chatbot developer speak” for the user’s desire for interacting with the virtual characters.
 When I initiate an interaction with a human, or a bot, I generally have
 a motivation to why I am speaking with them. I want to ask them the
weather forecast for tomorrow, or ask for help on my calculus homework.

In order for a virtual being to react to a user properly, it first has to learn what the user wants. The development of intent detection is a landscape filled with Machine
Learning nuts who will show off their fancy computer vision algorithms
and face detection classifiers. Intent can also be broken up into
context, and be given long and short term properties. The subject can
get complicated very quickly.

"<img src='/images/500x300.png'>"

<!-- wp:heading {"level":3} -->
*Action*
On the other side of the system, *an action* is an event (or function) that is triggered when the *intent* has been classified by the virtual character. The action is powered by
entities, or recognized components in the user’s communication.

In the example above, the action, motivated by intent, would trigger a series of functions that move the character to say “hello.” *Actions* have as much complexity as *Intent.* In
the short term, these actions will be “canned”, using pre-animated pieces of content. Undoubtedly these actions will become increasingly generated at real time, allowing the characters to generate the corresponding action on the fly.

<h3><strong>Bridging the Worlds</strong></h3>
Around 2 minutes and 30 seconds into the video at the top of the post, Edward
Saatchi (the CEO of Fable) says that there is a division between the AI community and the filmmaker community. This is true, and the division of Intent and Action cleanly
 divides the knowledge chasm that will need to be traversed in order to
see the mass propagation of virtual characters. Animators are going to
have to learn how to develop state machines for their actions, and Engineers are
going to have to learn to push beyond boolean if/then statements. Once we have both sides
communicating, the rest should come with time and focus.</p>

Let’s leave the ethics of all of it for another time!
<p>That’s it for this time. Thanks for reading. </p>
<!-- /wp:paragraph -->

<!-- wp:image {"linkDestination":"custom"} -->
<figure class="wp-block-image"><a href="https://cdn.substack.com/image/fetch/c_limit,f_auto,q_auto:good/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Febd08cd7-099f-4d28-9983-5adc452b9cc8_612x108.png" target="_blank" rel="noreferrer noopener"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Febd08cd7-099f-4d28-9983-5adc452b9cc8_612x108.png" alt=""/></a></figure>
<!-- /wp:image -->

<!-- wp:heading {"level":3} -->
<h3><strong>Reference and Links:</strong></h3>
<!-- /wp:heading -->

<!-- wp:paragraph -->
<p><strong>Fable Studio: </strong>https://fable-studio.com/</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p><strong>Oculus Story Studio</strong>: https://www.oculus.com/story-studio/</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p><strong>Virtual Beings Summit:</strong> https://www.virtual-beings-summit.com/</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p><strong>Chatbot vocabulary (like User Intent):</strong> https://chatbotsmagazine.com/chatbot-vocabulary-10-chatbot-terms-you-need-to-know-3911b1ef31b4</p>
<!-- /wp:paragraph -->

<!-- wp:paragraph -->
<p><strong>Dwayne Johnson (the Rock):</strong> https://en.wikipedia.org/wiki/Dwayne_Johnson</p>
<!-- /wp:paragraph -->

This is a test to see if the posting will work
======

Let's attempt to make some headings
======

This work?
------
